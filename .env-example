MODEL_PROVIDER=ollama
OLLAMA_MODEL=llama3.1:8b
VITE_PORT=5173
VITE_HOST=localhost
FLASK_PORT=5008
FLASK_HOST=localhost

# o per usare OpenAI:
# MODEL_TYPE=openai
# OPENAI_API_KEY=your-api-key-here
